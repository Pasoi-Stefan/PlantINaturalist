{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import pytorch_lightning as pl\n",
    "import torchinfo\n",
    "\n",
    "from PlantINaturalist2021DataModule import PlantINaturalist2021DataModule as imported_datamodule\n",
    "from PlantINaturalist2021FineTuneDensenet201 import PlantINaturalist2021FineTuneDensenet201 as imported_model\n",
    "from image_transformers import transform_autoaugment as imported_transform\n",
    "\n",
    "config = {\n",
    "    \"model_name\": imported_model.__name__,\n",
    "    \"num_classes\": 250,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lr_decay_epoch_step_size\": 5,\n",
    "    \"lr_decay_rate\": 0.9,\n",
    "    \"num_trainable_layers\": 3,\n",
    "    \"transform\": imported_transform.__name__,\n",
    "    \"batch_size\": 64\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sanity run\n",
    "pl.Trainer(max_steps=5).fit(model=imported_model(config), datamodule=imported_datamodule(transform=imported_transform.get(), context = \"retrain\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model and datamodule and module summary\n",
    "model = imported_model(config)\n",
    "\n",
    "datamodule = imported_datamodule(transform=imported_transform.get(), context=\"train\", batch_size=64, num_workers=2, pin_memory=True, data_dir=\"./\")\n",
    "\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust datamodule config\n",
    "datamodule = imported_datamodule(transform=imported_transform.get(), context=\"train\", batch_size=64, num_workers=2, pin_memory=True, data_dir=\"./\")\n",
    "\n",
    "trainer = pl.Trainer(benchmark=True, max_time=\"00:00:03:00\", accelerator='gpu', devices=1)\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more model info\n",
    "torchinfo.summary(model, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate run\n",
    "import wandb\n",
    "import torch\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "run = wandb.init(project='PlantINaturalist2', config=config)\n",
    "\n",
    "wandb.save(f\"{imported_model.__name__}.py\")\n",
    "wandb.save(f\"{imported_datamodule.__name__}.py\")\n",
    "wandb.save(\"image_transformers.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = pl.Trainer(benchmark=True, logger=wandb_logger, max_time=\"00:02:00:00\", accelerator='gpu', devices=1)\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save model as artifact to wandb\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parameters\n",
    "next(model.model.classifier.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetune and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "artifact = run.use_artifact('pasoi0stefan/PlantINaturalist/model:v11', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlantINaturalist2021DataModule import PlantINaturalist2021DataModule as imported_datamodule\n",
    "from PlantINaturalist2021FinetuneMobileNetv2 import PlantINaturalist2021FinetuneMobileNetv2 as imported_model\n",
    "from image_transformers import transform_autoaugment as imported_transform\n",
    "\n",
    "config = {\n",
    "    \"model_name\": imported_model.__name__,\n",
    "    \"num_classes\": 250,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lr_decay_epoch_step_size\": 5,\n",
    "    \"lr_decay_rate\": 0.9,\n",
    "    \"num_trainable_layers\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = imported_model(config)\n",
    "model_artifact.load_state_dict(torch.load(f\"{artifact_dir}/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINETUNE\n",
    "wandb_logger = WandbLogger()\n",
    "model_finetune = imported_model(config)\n",
    "print(next(model_finetune.model.classifier.parameters())[:2])\n",
    "model_finetune.load_state_dict(torch.load(f\"{artifact_dir}/model.pth\"))\n",
    "print(next(model_finetune.model.classifier.parameters())[:2])\n",
    "model_finetune.learning_rate = 0.001\n",
    "model_finetune.configure_optimizers()\n",
    "datamodule_finetune = imported_datamodule(transform=imported_transform.get(), context=\"finetune\", batch_size=32, num_workers=1, pin_memory=True, data_dir=\"./\")\n",
    "trainer = pl.Trainer(benchmark=True, logger=wandb_logger, max_epochs = 20, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model_finetune, datamodule=datamodule_finetune)\n",
    "torch.save(model_finetune.state_dict(), 'finetuned_model.pth')\n",
    "artifact = wandb.Artifact('finetuned_model', type='model')\n",
    "artifact.add_file('finetuned_model.pth')\n",
    "run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINETUNE 2\n",
    "wandb_logger = WandbLogger()\n",
    "model_finetune = imported_model(config)\n",
    "print(next(model_finetune.model.classifier.parameters())[:2])\n",
    "model_finetune.load_state_dict(torch.load(f\"{artifact_dir}/model.pth\"))\n",
    "print(next(model_finetune.model.classifier.parameters())[:2])\n",
    "model_finetune.configure_optimizers()\n",
    "datamodule_finetune = imported_datamodule(transform=imported_transform.get(), context=\"retrain\", batch_size=32, num_workers=1, pin_memory=True, data_dir=\"./\")\n",
    "trainer = pl.Trainer(benchmark=True, logger=wandb_logger, max_epochs = 10, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model_finetune, datamodule=datamodule_finetune)\n",
    "torch.save(model_finetune.state_dict(), 'finetuned_model2.pth')\n",
    "artifact = wandb.Artifact('finetuned_model2', type='model')\n",
    "artifact.add_file('finetuned_model2.pth')\n",
    "run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRAIN\n",
    "wandb.finish()\n",
    "run = wandb.init()\n",
    "wandb_logger = WandbLogger()\n",
    "model_retrain = imported_model(config)\n",
    "datamodule_retrain = imported_datamodule(transform=imported_transform.get(), context=\"retrain\", batch_size=32, num_workers=1, pin_memory=True, data_dir=\"./\")\n",
    "trainer = pl.Trainer(benchmark=True, logger=wandb_logger, max_epochs = 40, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model_retrain, datamodule=datamodule_retrain)\n",
    "torch.save(model_retrain.state_dict(), 'retrained_model.pth')\n",
    "artifact = wandb.Artifact('retrained_model', type='model')\n",
    "artifact.add_file('retrained_model.pth')\n",
    "run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_artifact.model.classifier.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ddb299a13d2af08c67c36ca20e80947019e09e59494d2443849c5940fcefaa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
